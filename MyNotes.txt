Week of 11/10:

---> Please try to query TEMPEST via API (.env) at some point. 

For running YOLO, I have a couple edge GPUS (NVIDIA Jetson Nano and Orin AGX) that we could try using for a standalone device if you thought that was interesting.
The better solution is probably a script that checks the latest webcam footage and runs on one of our lab workstations, but it could be an interesting side project.
You wouldn't need a login to use the API, but you'll need the personal access token and the station/device ID.

--> Hydrophone data may need to be synchronized with meteorological data (OFFSET) Implement this

--> Implement stdin and stdout for wav_split and snap_hydrophone_processing. (DONE)

--> Featurize the spectrogram plots for machine learning use. (Make them be convertable to PNGs... etc)

--> Get with Evan on checking the calculations of dB; some calculations seem off.

--> Duty cycling functionality added to wav_split.

--> Ambient levels at: 
          - 1.5 kHz
          - 7.5 kHz
          -  15 kHz

 Address data sizing issue likely normalization calculations failing because of large array allocation (RAM?):
numpy.core._exceptions.MemoryError: Unable to allocate 16.3 GiB for an array with shape (547421756, 4) and data type float64

-------------------------------------------------------------------------------------------------------------------
Week of 09/29:
Here's the part to mimic in Python:
     % compute spectra (really spectrogram, time+freq)
            [~,f_Hz,~,psd] = spectrogram(data_T,fs,0,fs,fs,'psd');
   
            % convert to dB
            psd_db = 10*log10(psd)+gain; %in dB, adding the gain
           
            % find median values (avoids spiking)
            mS = median(psd_db,2,'omitnan');
               
            % decimate to reduce frequency resolution
            f_kHz = decimate(f_Hz, 100)./1000;
            mS = decimate(mS, 100);
    

from: https://github.com/SASlabgroup/SWIFT-codes/blob/master/Hydrophone/add_SNP.m

should be same as; https://github.com/SASlabgroup/SWIFT-codes/blob/master/Hydrophone/SNAP_hydrophone_processing.m

check sample rate, might be 96 kHz, should be available when you load the wav file.

--------------------------------------------------------------------------------------------------------------------
Important things to compute:

- 1-20 kHz overall level
Two steps:
1. Apply filter (either high & low OR band pass filter)
from scipy.signal import butter, filtfilt
# Butterworth filter parameters
order = 4
cutoff_freq = 100  # Hz - UPDATE THIS
btype = 'lowpass' # UPDATE THIS
nyquist_freq = 0.5 * fs
normalized_cutoff = cutoff_freq / nyquist_freq
b, a = butter(order, normalized_cutoff, btype=btype, analog=False)
filtered_signal = filtfilt(b, a, original_signal)

--------------------------------------------------------------------------------------------------------------------

2. Compute root mean square level
Square all values, take mean along time axis, square root that value. Maybe convert to decibels after (20(log10(pressure in pascals/(10^-6 pascals))


- Spectra
from scipy.signal import welch
frequencies, psd = welch(signal, fs, nperseg=256, noverlap=128)

We should update nperseg and noverlap. Keep noverlap at nperseg/2. Try some different things, but don't go over sampling frequency. Try 1024, 2048, etc.

Reference for windowing: https://download.ni.com/evaluation/pxi/Understanding%20FFTs%20and%20Windowing.pdf

-------------------------------------------------------------------------------------------------------------------
Week of 09/22: https://github.com/SASlabgroup/SWIFT-codes/tree/master/Hydrophone