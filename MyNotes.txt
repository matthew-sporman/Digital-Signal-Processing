Week of 1/5/26:

--> If you need any direction, I'd say try to open the .nc or .mat files and process the audio files at time steps that match the meteorological data there,
then save the spectrums and levels to some kind of file (.csv or whatever) and maybe try doing some figures comparing wind speed or wave height to the audio levels. 
-------------------------------------------------------------------------------------------------------------------
Week of 12/8:

--> https://acousticalsociety.org

--> JSON formatting reference for Tempest API: https://apidocs.tempestwx.com/reference/observation-record-format

--> (DONE) Fix the massive array size allocation issue:  
plt.savefig(os.path.join(save_path, "spectrogram.png"), dpi=200)
issue is with line above. We have to do something about the time array size to shrink it for this figure to save.

Stack Trace:
Saved processed data to D:\Hydromoth_Data\output_charts\SNAPhydrophonespectra_fft.npz

STDERR: Traceback (most recent call last):
  File "C:\Users\matth\OneDrive\Documents\GitHub\Digital-Signal-Processing\snap_hydrophone_processing.py", line 198, in <module>
    main(wav_folder=args.input_dir,
  File "C:\Users\matth\OneDrive\Documents\GitHub\Digital-Signal-Processing\snap_hydrophone_processing.py", line 142, in main
    plt.savefig(os.path.join(save_path, "spectrogram.png"), dpi=200)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\pyplot.py", line 1251, in savefig
    res = fig.savefig(*args, **kwargs)  # type: ignore[func-returns-value]
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\figure.py", line 3490, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\backends\backend_qtagg.py", line 75, in print_figure
    super().print_figure(*args, **kwargs)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\backend_bases.py", line 2157, in print_figure  
    self.figure.draw(renderer)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\artist.py", line 94, in draw_wrapper
    result = draw(artist, renderer, *args, **kwargs)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\artist.py", line 71, in draw_wrapper
    return draw(artist, renderer)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\figure.py", line 3257, in draw
    mimage._draw_list_compositing_images(
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\image.py", line 134, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\artist.py", line 71, in draw_wrapper
    return draw(artist, renderer)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\axes\_base.py", line 3226, in draw
    mimage._draw_list_compositing_images(
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\image.py", line 134, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\artist.py", line 71, in draw_wrapper
    return draw(artist, renderer)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\collections.py", line 2423, in draw
    self.update_scalarmappable()
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\collections.py", line 923, in update_scalarmappable
    self._mapped_colors = self.to_rgba(self._A, self._alpha)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\colorizer.py", line 367, in to_rgba
    return self._colorizer.to_rgba(x, alpha=alpha, bytes=bytes, norm=norm)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\colorizer.py", line 158, in to_rgba
    rgba = self.cmap(x, alpha=alpha, bytes=bytes)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\colors.py", line 740, in __call__
    rgba, mask = self._get_rgba_and_mask(X, alpha=alpha, bytes=bytes)
  File "C:\ProgramData\miniconda3\envs\Digital-Signal-Processing\lib\site-packages\matplotlib\colors.py", line 798, in _get_rgba_and_mask    
    rgba = lut.take(xa, axis=0, mode='clip')
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 51.4 GiB for an array with shape (811, 2126187, 4) and data type float64 

--> "D:\SWIFT12_2024Oct27-31_HLY2403(1).zip"
    Load .mat files using python for getting weather observations from arctic buoys up by Alaska.

--> (DONE) Featurize the spectrogram plots for machine learning use. (Make them be convertable to PNGs... etc)

--> Synchronization of weather to observations ("this is the weather at the same time as this point in the spectrogram)

--> (DONE) Event-based flags; If we have an object detection model, we can say "there's a ship" going by at some specific point in time.
    this will lead into the machine learning portion of the project later.

--> Get with Evan on checking the calculations of dB; some calculations seem off.

--> Ambient levels at: 
          - 1.5 kHz
          - 7.5 kHz
          -  15 kHz

--> (Octave?) band anaylsis

-------------------------------------------------------------------------------------------------------------------
Week of 11/10:
---> Please try to query TEMPEST via API (.env) at some point.
Curl: "https://swd.weatherflow.com/swd/rest/observations/station/[your_station_id]?token=[your_access_token]"
Station is 82486
Key you should already have (DONE)

Here's some info about the Audiomoth sensitivity which relates to the gain: https://bioacoustics.stackexchange.com/questions/558/what-is-the-audiomoth-absolute-sensitivity-in-v-pa?rq=1

For running YOLO, I have a couple edge GPUS (NVIDIA Jetson Nano and Orin AGX) that we could try using for a standalone device if you thought that was interesting.
The better solution is probably a script that checks the latest webcam footage and runs on one of our lab workstations, but it could be an interesting side project.
You wouldn't need a login to use the API, but you'll need the personal access token and the station/device ID.

--> Hydrophone data may need to be synchronized with meteorological data; Offset needs to be a synchronization feature. (DONE)

--> Implement stdin and stdout for wav_split and snap_hydrophone_processing. (DONE)

--> Duty cycling functionality added to wav_split. (DONE)

 Address data sizing issue likely normalization calculations failing because of large array allocation (RAM?):
numpy.core._exceptions.MemoryError: Unable to allocate 16.3 GiB for an array with shape (547421756, 4) and data type float64

-------------------------------------------------------------------------------------------------------------------
Week of 09/29:
Here's the part to mimic in Python:
     % compute spectra (really spectrogram, time+freq)
            [~,f_Hz,~,psd] = spectrogram(data_T,fs,0,fs,fs,'psd');
   
            % convert to dB
            psd_db = 10*log10(psd)+gain; %in dB, adding the gain
           
            % find median values (avoids spiking)
            mS = median(psd_db,2,'omitnan');
               
            % decimate to reduce frequency resolution
            f_kHz = decimate(f_Hz, 100)./1000;
            mS = decimate(mS, 100);
    

from: https://github.com/SASlabgroup/SWIFT-codes/blob/master/Hydrophone/add_SNP.m

should be same as; https://github.com/SASlabgroup/SWIFT-codes/blob/master/Hydrophone/SNAP_hydrophone_processing.m

check sample rate, might be 96 kHz, should be available when you load the wav file.

--------------------------------------------------------------------------------------------------------------------
Important things to compute:

- 1-20 kHz overall level
Two steps:
1. Apply filter (either high & low OR band pass filter)
from scipy.signal import butter, filtfilt
# Butterworth filter parameters
order = 4
cutoff_freq = 100  # Hz - UPDATE THIS
btype = 'lowpass' # UPDATE THIS
nyquist_freq = 0.5 * fs
normalized_cutoff = cutoff_freq / nyquist_freq
b, a = butter(order, normalized_cutoff, btype=btype, analog=False)
filtered_signal = filtfilt(b, a, original_signal)

--------------------------------------------------------------------------------------------------------------------

2. Compute root mean square level
Square all values, take mean along time axis, square root that value. Maybe convert to decibels after (20(log10(pressure in pascals/(10^-6 pascals))


- Spectra
from scipy.signal import welch
frequencies, psd = welch(signal, fs, nperseg=256, noverlap=128)

We should update nperseg and noverlap. Keep noverlap at nperseg/2. Try some different things, but don't go over sampling frequency. Try 1024, 2048, etc.

Reference for windowing: https://download.ni.com/evaluation/pxi/Understanding%20FFTs%20and%20Windowing.pdf

-------------------------------------------------------------------------------------------------------------------
Week of 09/22: https://github.com/SASlabgroup/SWIFT-codes/tree/master/Hydrophone
